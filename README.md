
# Mighty Moo – Adversarial Prompt Writing with Ground Truth Validation  
**(Outlier.ai | Generative Image-to-Text Model Evaluation)**

This repository documents my work on the **Mighty Moo** project under **Outlier.ai**, where I contributed to evaluating and stress-testing image-to-text generative models by crafting adversarial prompts and validating against ground truth data.

---

## 🧠 Project Overview

The goal of the Mighty Moo project was to test the limits of a multimodal LLM’s ability to interpret and describe visual inputs accurately. I was responsible for uploading real-world images and writing **complex or misleading prompts** designed to expose weaknesses in the model’s visual reasoning capabilities.

The task required high attention to detail, an understanding of **visual semantics**, and a strong grasp of **ground truth verification**.

---

## 🔧 Key Responsibilities

- **Image-Based Prompt Engineering:** Uploaded diverse and complex images (e.g., charts, crowded scenes, layered objects) to challenge the model's understanding.
- **Adversarial Prompt Writing:** Crafted deliberately difficult prompts (misleading, vague, or multi-faceted) that would cause the model to produce incorrect, hallucinated, or biased responses.
- **Ground Truth Validation:** Knew the correct answer (ground truth) and used it as a reference to judge the model’s output accuracy and failure mode.
- **Failure Case Identification:** Detected subtle issues in model responses such as:
  - Hallucinations (describing something that wasn't in the image)
  - Ambiguity or vagueness
  - Logical inconsistencies in spatial or object relationships
- **Documentation:** Tagged model failures and described why the model was wrong, helping developers improve model performance and robustness.

---

## 🧪 Example Task Flow

1. Upload an image of a grocery shelf with overlapping items.
2. Write a misleading prompt like:  
   _“How many red soda cans are facing forward on the second row?”_
3. Analyze the model's response.
4. Compare it to the actual answer (known from the image).
5. Mark the output as incorrect and document the failure mode.

---

## 📌 Skills Demonstrated

- Prompt engineering for multimodal models (image-to-text)
- Ground truth analysis and attention to visual detail
- Adversarial testing and stress-case generation
- Model evaluation and safety analysis
- Use of internal tools under quality benchmarks

---

## 🚀 Impact

- Helped identify weaknesses in visual-text model understanding and generalization.
- Supported fine-tuning and failure mode documentation for real-world deployment.
- Contributed to model safety efforts through controlled adversarial examples.

---

## 👨‍💻 Author

**Satyam Raj**  
Multimodal Evaluator | Prompt Engineer  
- Outlier.ai – Project Mighty Moo  
- Email: [your.email@example.com]  
- GitHub: [https://github.com/yourusername]
